import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv("churn_data.csv")
data.head(10)

#Exploratory Data Analysis

data.shape

data.info()

data.describe()

#Checking the number of null values in each feature

#data.isnull().any()
data.isnull().sum()

#I removed the 4 null values form the feature "age"

data=data[pd.notnull(data["age"])]

data=data.drop(columns=["credit_score","rewards_earned"])
data.head(10)

data.drop(columns=["churn","user","housing","zodiac_sign","payment_type"],axis=1).corrwith(data["churn"]).plot.bar(figsize=(20,10),title=("corellation of churn with respect to other features"))

cm=data.corr()
sns.heatmap(cm)

user_identifier=data["user"]
dataset=data.drop(columns=["user"])

dataset["housing"].value_counts()
dataset=pd.get_dummies(dataset)
dataset.columns

dataset.drop(columns=["zodiac_sign_na","housing_na","payment_type_na"]).head(10)

from sklearn.model_selection import train_test_split
y=dataset["churn"]
x=dataset.drop(columns=["churn"],axis=1)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

y_train.value_counts()

#Feature Balancing in the x_Train and x_test dataset

pos_index=y_train[y_train.values==1].index
neg_index=y_train[y_train.values==0].index

if len(pos_index) > len(neg_index):
    higher=pos_index
    lower=neg_index
else:
    higher=neg_index
    lower=pos_index
    
higher=np.random.choice(higher,size=len(lower))
lower=np.asarray(lower)
#print(higher.shape)
#print(lower.shape)

new_index=np.concatenate((higher,lower))
x_train=x_train.loc[new_index,]
y_train=y_train.loc[new_index]

#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train2=pd.DataFrame(sc.fit_transform(x_train))
x_test2=pd.DataFrame(sc.fit_transform(x_test))
x_train2.columns=x_train.columns.values
x_test.columns=x_test.columns.values
x_train2.index=x_train.index.values
x_test.index=x_test.index.values
x_train=x_train2
x_test=x_test2
print(x_train.shape)
print(y_train.shape)


from sklearn.linear_model import LogisticRegression
logit=LogisticRegression()
logit.fit(x_train,y_train)
y_pred=logit.predict(x_test)

from sklearn.metrics import classification_report,confusion_matrix
print(classification_report(y_test,y_pred))

cm=confusion_matrix(y_test,y_pred)
print(cm)

df_cm=pd.DataFrame(cm,index=(0,1),columns=(0,1))
plt.figure(figsize=(10,7))
sns.heatmap(df_cm,annot=True,fmt='g')

y_test.shape
y_pred.shape

final_results=pd.DataFrame(columns=["Actual result","Predicted result"])
final_results["Actual result"]=y_test
final_results["Predicted result"]=y_pred
final_results
